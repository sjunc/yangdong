# ================================================================
# llm_client.py
# ------------------------------------------------
# ğŸ§  ì—­í• :
# - GPT-4o-mini (ë˜ëŠ” ì§€ì •ëœ ëª¨ë¸)ê³¼ì˜ ëŒ€í™” ê¸°ëŠ¥ ì œê³µ
# - ëª¨ë“  LLM ê´€ë ¨ í˜¸ì¶œì„ ì´ íŒŒì¼ë¡œ í†µí•©
# - ë‹¤ë¥¸ í”„ë¡œì íŠ¸(ì˜ˆ: STT/TTS, RAG ë“±)ì—ì„œ import í•˜ì—¬ ì‚¬ìš©
# ================================================================

from openai import OpenAI
from typing import List, Dict, Any
from .config import settings

# ------------------------------------------------
# ğŸ”— OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# ------------------------------------------------
_client = OpenAI(
    api_key=settings.openai_api_key,
    base_url=settings.openai_base_url
)

# ------------------------------------------------
# ğŸ’¬ Chat í•¨ìˆ˜ (LLM ëŒ€í™”ìš©)
# ------------------------------------------------
def chat(messages: List[Dict[str, str]],
         model: str | None = None,
         temperature: float = 0.7,
         max_tokens: int = 256) -> str:
    """
    GPT-4o-mini ëª¨ë¸ì— ì±„íŒ… ìš”ì²­ì„ ë³´ë‚´ê³ , í…ìŠ¤íŠ¸ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        messages: OpenAI chat í˜•ì‹ì˜ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
                  ì˜ˆ: [{"role": "user", "content": "ì•ˆë…•"}]
        model: ì‚¬ìš©í•  ëª¨ë¸ëª… (ê¸°ë³¸ê°’ì€ .envì— ì„¤ì •ëœ ëª¨ë¸)
        temperature: ì°½ì˜ì„± ì •ë„ (0=ë³´ìˆ˜ì , 1=ì°½ì˜ì )
        max_tokens: ìµœëŒ€ ìƒì„± í† í° ìˆ˜

    Returns:
        str: LLMì´ ìƒì„±í•œ ë‹µë³€ í…ìŠ¤íŠ¸
    """
    model = model or settings.openai_model
    resp = _client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens
    )
    return resp.choices[0].message.content.strip()
